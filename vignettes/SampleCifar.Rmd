---
title: "Processing Cifar-10"
author: "Anthony A"
date: "12/3/2022"
output: 
  html_document:
    code_folding: show
    highlight: espresso
    number_sections: true
    smart: false
    theme: sandstone
    toc: true
    toc_float: 
      collapsed: false
      smooth_scroll: false
---

# Abstract

We develop a data pipeline capable of processing pictures for image classification purposes.
Our motive for this technology is to identify objects in scenarios such as televised sports and security.

```{r setup, include=FALSE, warning=FALSE}
library(magrittr)
library(here)
library(reshape2)
library(ggplot2)
library(dplyr)
invisible(lapply(list.files(here::here("R"), "\\.R$", full.names = TRUE), source))
```

# Datasets

Image classification is usually started with microsized images and scaled up from there.

## CIFAR-10

The CIFAR-10 dataset is a well known data consisting of ten different classes of color images.
These classes include automobiles, deer, and horses.
The images have very little processing and are scaled down to 32x32 pixels large.
There are 60 thousand images, of which they are proportioned evenly between all 10 classes.
Additionally, the order in the training set is random and resampling is always good practice.

## CIFAR-100

The CIFAR-100 dataset is a sister dataset to the original CIFAR-10 dataset.
It has largely the same specifications except it has two labels, a major and minor one.

# Exploratory Data Analysis

For this project, we use the binary version of the files so the following paths are provided.

```{r, class.source = 'fold-hide'}
Cifar100Path <- function() {
  "data/cifar-100-binary/cifar-100-binary"
}
```

## File Specifications

According to the CIFAR-10 binary specification, each image has one label and 3072 pixels embedded in each batch file.
We can confirm that each batch contains ten thousand images by checking the file properties.
Two implementations are shown below to verify this.

```{r}
CountImages(CifarTrain(), 1 + 3072)
CountImagesByPixel(CifarTrain(), 1024, 3, 1)
```

## Pointer Arithmetic

Since our images are concatenated together, we can use some arithmetic to determine the binary position.
This will help set our pointer when we read each image into a matrix.

```{r}
head(FindPos(file.size(CifarTrain()[1]), 3073))
```

## Retrieving Labels

We can verify that this works as intended by first defining our scanner and then how to interop.
Specifically, we have to read a secondary file in the metadata to get the names of our labels.
In this scenario, the row number or index corresponds to the class id out of convenience.
Otherwise, we would have to do a left join here to accomplish the same goal.
After reading the binary data, we have a 1xM matrix for all of the labels in CIFAR-10.
This will actually be vectorized to read all of the files later instead of only one.

```{r}
imageFile <- file(CifarTrain()[1], "rb")
cifarLabels = sapply(FindPos(10000, 3073), Label, imageFile) %>%
  data.frame(labels = .) %>%
    NumbersToLabels(., CifarLabelnames())
invisible(close(imageFile))

head(cifarLabels[[1]])
```

## Retrieving Images

Before we vectorize that function, let's also take a look at our image data.
As discussed, the image is 3072 pixels large.
This corresponds to 1024 red bytes, 1024 green bytes, and 1024 blue bytes.
Our definition to parse this creates a three dimensional matrix that organizes all of this data.

```{r}
imageFile <- file(CifarTrain()[1], "rb")
cifarData = lapply(FindPos(10000, 3073), Image, imageFile, 1024L, 3L, 1L)
invisible(close(imageFile))

str(cifarData[1:6])
```

# Data Transformations

For our data, it produces a matrix with 1024x3xM dimensions, representing pixels, channel, and count:
 x such that imagePixels, the value 0 to 255 of one pixel, top to bottom, left to right;
 y such that imageChannels, three columns correspond to the rgb channels in an image;
 z such that imageCount, separates each image to a layer.

```{r}
UnlistDims(cifarData) %>%
  str()
```

## Transform to Filter Green

In order to fully appreciate what this data structure is, let's suppose that we wanted to filter green.
This data structure can do that extremely easily because the green channel is in m[,2,] here.

```{r}
FilterGreen <- function(m) {
  m[,2,] = 0
  m
}

UnlistDims(cifarData) %>%
  FilterGreen(.) %>%
    .[,,1] %>%
      head()
```

## Visualization of Green Filter

Just in case you are skeptical, we can quickly visualize the distribution of color present.
Shown in the graph is the three different color channels: red, green, and blue.

```{r}
CoerceLabel <- function(m, groupname) {
  df = mapply(1:3, c("red", "green", "blue"), FUN = function(x, y) {
    values = list(as.vector(m[,x,]))
    names(values) = y
    
    values
  }) %>%
    do.call(cbind, .) %>%
      data.frame(.) %>%
        dplyr::mutate(group = groupname)
}

set.seed(8675309) %>%
  { rbind(
    UnlistDims(cifarData) %>% 
      CoerceLabel("Pre Green Filter"),
    UnlistDims(cifarData) %>% 
      FilterGreen(.) %>% 
        CoerceLabel("Post Green Filter")
  ) } %>%
    reshape2::melt(id = "group") %>%
      .[sample.int(nrow(.), 1000), ] %>%
        ggplot2::ggplot(.) +
        ggplot2::aes(x = variable, y = value, fill = group) +
        ggplot2::geom_boxplot(shape = "circle") +
        ggplot2::scale_fill_hue(direction = 1) +
        ggplot2::theme_minimal()
```

## Preparing for Modeling

Since most models take two dimensional data like data frames, we can reduce the dimensions from three to two.
This gives us the original dimensions present in the binary file.
However, since this process is separate, we can keep all of our transforms from previously.

```{r}
modelReadyCifar = UnlistDims(cifarData) %>%
  FilterGreen(.) %>%
    ThreeToTwoDims(.)

str(modelReadyCifar)
```

# Analysis and Output

Finally, let's vectorize our whole process now that we know that everything works as intended.
We want to vectorize the reading of files first. 
Afterwards, we double check that our interop functions are distinct and can handle unintentional args.
Thus, we coerce everything to follow a template and we are done.

```{r}
finalLabels = ReadCifarLabels(CifarTest()) %>%
  unlist() %>%
    data.frame(labels = .) %>%
      NumbersToLabels()

finalResults = ReadCifarData(CifarTest(), simplify = FALSE) %>%
  FilterGreen(.) %>%
    ThreeToTwoDims(.) %>%
      data.frame(.) %>%
        cbind(finalLabels, .)

str(finalResults, list.len = 6)
finalResults[1:6, 1:6]
```

## Verification of portability

From the same resource, we can also get the CIFAR-100 dataset with 100 classes and 2 sets of labels.
These are also 32x32 images so theoretically, we should be able to get the same results with minor changes.
One thing of note, we have to write an additional labeling function to make it vectorized.
Afterwards, it works exactly as expected.

```{r}
proofFinalLabels = ReadCifarMultiLabels(CifarTest(filepath = Cifar100Path(), pattern = "test.bin"), imageLabels = 2L) %>%
  unlist() %>%
    data.frame(labels = .) %>%
      NumbersToLabels(., CifarLabelnames(filepath = Cifar100Path(), pattern = ".*label_names.txt")) 

proofFinalResults = ReadCifarData(CifarTest(filepath = Cifar100Path(), pattern = "test.bin"), simplify = FALSE) %>%
  FilterGreen(.) %>%
    ThreeToTwoDims(.) %>%
      data.frame(.) %>%
        cbind(proofFinalLabels, .)

str(proofFinalResults, list.len = 6)
proofFinalResults[1:6, 1:6]
```

# References

CIFAR-10 and CIFAR-100 are both due credit to Alex Krizhevsky, 2009.
The tech report can be accessed here to find the dataset and methodology: 
Learning Multiple Layers of Features from Tiny Images, 
https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf
An additional website owned by them can be found at this link:
https://www.cs.toronto.edu/~kriz/cifar.html
